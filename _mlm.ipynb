{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df010284-0bfd-442f-9a96-dce4830594ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910e696-4bce-4bb2-87c7-072da9f151ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "from masked_models.utils import sentence_logprob, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f91cc-6ffb-4568-abf4-cbc0422df5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "stereotypes = []\n",
    "\n",
    "for line in open('./data/samples.txt'):\n",
    "    words = line.split()\n",
    "    sentences.append(' '.join(words[:-1]))\n",
    "    stereotypes.append(int(words[-1]))\n",
    "\n",
    "stereo_names = \"\"\"\n",
    "Emotional\n",
    "Gentle\n",
    "Empathetic\n",
    "Neat\n",
    "Social\n",
    "Weak\n",
    "Beautiful\n",
    "Tough and rough\n",
    "Self-confident\n",
    "Professional\n",
    "Rational\n",
    "Providers\n",
    "Leaders\n",
    "Childish\n",
    "Sexual\n",
    "Strong\n",
    "\"\"\".strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6bda81-5fcf-4905-9d48-a99ca5c062ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translators.google_translate import GoogleTranslate\n",
    "from translators.amazon_translate import AmazonTranslate\n",
    "from translators.deepl import DeepL\n",
    "\n",
    "translators = [\n",
    "    AmazonTranslate(\n",
    "        data_path='./cache/translations/amazon_translate',\n",
    "        target_language='sk',\n",
    "        enable_api=False,\n",
    "    ).load(),\n",
    "    DeepL(\n",
    "        data_path='./cache/translations/deepl',\n",
    "        target_language='sk',\n",
    "        enable_api=False,\n",
    "    ).load(),\n",
    "    GoogleTranslate(\n",
    "        data_path='./cache/translations/google_translate',\n",
    "        target_language='sk',\n",
    "        enable_api=False,\n",
    "    ).load(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736d40c-c9fa-435e-91f4-62853916fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translators.helpers import gender_translate\n",
    "\n",
    "suffixes = [\n",
    "    ('', 'a'),      # robil > robila\n",
    "    ('ol', 'la'),   # mohol > mohla\n",
    "    ('ý', 'á'),     # pekný > pekná\n",
    "    ('y', 'a'),     # odvážny > odvážna\n",
    "    ('i', 'a'),     # ohromujúci > ohromujúca\n",
    "    ('í', 'ia'),    # lepší > lepšia\n",
    "    ('iel', 'la'),  # išiel > išla\n",
    "    ('ým', 'ou'),   # šťastným > šťastnou\n",
    "    ('', 'ka'),     # amatér > amatérka\n",
    "    ('om', 'kou'),  # víťazom > víťazkou\n",
    "    ('k', 'čka'),   # odborník > odborníčka\n",
    "    ('ného', 'nú'), # neschopného > neschopnú\n",
    "    ('ím', 'ou'),   # šťastnejším šťastnejšou\n",
    "    ('í', 'ie'),    # efektívnejší > efektívnejšie\n",
    "    ('í', 'é'),     # zlí > zlé       \n",
    "    ('rád', 'rada'), \n",
    "    ('sám', 'sama'), \n",
    "]    \n",
    "\n",
    "def match_gender(male, female):\n",
    "    male = male.lower().strip('.').strip(',').strip('?').strip('!')\n",
    "    female = female.lower().strip('.').strip(',').strip('!')\n",
    "\n",
    "    return any(\n",
    "       (\n",
    "            # or None is here to handle the case when we have zero suffix\n",
    "            # str[:-0] will return empty string\n",
    "            # str[:None] will return the entire string\n",
    "            female[:-len(female_suffix)] == male[:-len(male_suffix) or None] and\n",
    "            male.endswith(male_suffix)\n",
    "            and female.endswith(female_suffix)\n",
    "        )\n",
    "        for male_suffix, female_suffix in suffixes\n",
    "    )\n",
    "\n",
    "candidates = []\n",
    "x = 0\n",
    "for sentence, stereotype in zip(sentences, stereotypes):\n",
    "    for translator in translators:\n",
    "        m, f = gender_translate(sentence, translator, 'male'), gender_translate(sentence, translator, 'female')\n",
    "        if m is None or f is None:\n",
    "            continue\n",
    "        m_words = m.split()\n",
    "        f_words = f.split()\n",
    "        if len(m_words) == len(f_words) and sum(mw != fw for mw, fw in zip(m_words, f_words)) == 1:\n",
    "            for mw, fw in zip(m_words, f_words):\n",
    "                if mw != fw:\n",
    "                    if match_gender(mw, fw):\n",
    "                        candidates.append((m, f, stereotype))\n",
    "                    break\n",
    "\n",
    "candidates = set(candidates)\n",
    "len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a1287-6bc3-4e16-967c-fdf399706a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(c[2] for c in candidates).most_common(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2aff0-b94f-49cc-8100-15b592eb883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(model_name):\n",
    "    model, tokenizer = AutoModelForMaskedLM.from_pretrained(model_name), AutoTokenizer.from_pretrained(model_name)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to('cuda:0')\n",
    "    return model, tokenizer\n",
    "\n",
    "def tokenize(sen, tokenizer, only_ids=False, **kwargs):\n",
    "    batch_encoding = tokenizer(sen, return_tensors=\"pt\", **kwargs)\n",
    "    return batch_encoding['input_ids'][0].tolist()\n",
    "\n",
    "def bootstrap_ci(scores, alpha=0.95):\n",
    "    \"\"\"\n",
    "    Bootstrapping based estimate.\n",
    "    \n",
    "    Return mean and confidence interval (lower and upper bound)\n",
    "    \"\"\"\n",
    "    loc, scale = norm.fit(scores)    \n",
    "    bootstrap = [sum(random.choices(scores, k=len(scores))) / len(scores) for _ in range(1000)]\n",
    "    lower, upper = norm.interval(alpha, *norm.fit(bootstrap))\n",
    "        \n",
    "    return loc, lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637bdb29-ce0e-4728-bffe-79a9e58211c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_size(w,h, ax=None):\n",
    "    \"\"\"\n",
    "    Used to size the figures with subplots\n",
    "    \n",
    "    https://stackoverflow.com/questions/44970010/axes-class-set-explicitly-size-width-height-of-axes-in-given-units\n",
    "    \"\"\"\n",
    "    if not ax: ax=plt.gca()\n",
    "    l = ax.figure.subplotpars.left\n",
    "    r = ax.figure.subplotpars.right\n",
    "    t = ax.figure.subplotpars.top\n",
    "    b = ax.figure.subplotpars.bottom\n",
    "    figw = float(w)/(r-l)\n",
    "    figh = float(h)/(t-b)\n",
    "    ax.figure.set_size_inches(figw, figh)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "for model_handle, model_name, ax in zip(\n",
    "    ['gerulata/slovakbert', 'bert-base-multilingual-cased', 'xlm-roberta-base', 'xlm-roberta-large'],\n",
    "    ['SlovakBERT', 'mBERT', 'XLM-RoBERTa Base', 'XLM-RoBERTa Large'],\n",
    "    axes\n",
    "):\n",
    "    model, tokenizer = model_init(model_handle)\n",
    "\n",
    "    scores = []\n",
    "    for c1, c2, s in tqdm(list(candidates)):\n",
    "        if len(tokenize(c1, tokenizer)) != len(tokenize(c2, tokenizer)):\n",
    "            continue\n",
    "        a = sentence_logprob(c1, c2, tokenizer, model)\n",
    "        b = sentence_logprob(c2, c1, tokenizer, model)\n",
    "        scores.append((a-b, s))\n",
    "    \n",
    "    for i in range(1, 17):\n",
    "        l, m, u = bootstrap_ci([score for score, stereotype_id in scores if stereotype_id == i])\n",
    "        ax.plot([l, u], [17-i, 17-i], c=('pink' if i < 8 else 'lightblue'))\n",
    "\n",
    "    male_rate = np.mean([score for score, stereotype_id in scores if stereotype_id >= 8])\n",
    "    female_rate = np.mean([score for score, stereotype_id in scores if stereotype_id < 8])\n",
    "    print(male_rate, female_rate)\n",
    "    ax.vlines(male_rate, 1, 16, linestyle=':', color='lightblue')\n",
    "    ax.vlines(female_rate, 1, 16, linestyle=':', color='pink')\n",
    "    \n",
    "    ax.set_yticks(range(1, 17), stereo_names[::-1])\n",
    "    ax.grid(visible=True, which='major', axis='y', c='lightgrey', linewidth=0.2)\n",
    "    ax.set_title(model_name)\n",
    "\n",
    "set_size(5, 6)\n",
    "fig.subplots_adjust(left=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('lms.png', dpi=300)\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45220de5-1590-4c87-8d58-3982854d73bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
